{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sankalp\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv('Cricket3.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Converting words to integer values\n",
    "ground=pd.get_dummies(df['Ground'])\n",
    "pitch=pd.get_dummies(df['Pitch'])\n",
    "opponent=pd.get_dummies(df['Opponent'])\n",
    "weather=pd.get_dummies(df['Weather'])\n",
    "homeaway=pd.get_dummies(df['Home Away'])\n",
    "\n",
    "df.drop(['Home Away','Name','Sr.No.','Runs','Ground','Pitch','Fours','Sixes','Strike Rate','Opponent','Weather'],axis=1,inplace=True)\n",
    "\n",
    "df=pd.concat([df,ground,pitch,opponent,weather,homeaway],axis=1)\n",
    "\n",
    "X=df.drop('Result',axis=1)\n",
    "\n",
    "y=df['Result']\n",
    "\n",
    "#Splitting Training and Test Set\n",
    "#Since we have a very small dataset, we will train our model with all availabe data.\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel=RandomForestClassifier()\n",
    "\n",
    "#Fitting model with trainig data\n",
    "rfmodel.fit(X, y)\n",
    "\n",
    "# Saving model to disk\n",
    "pickle.dump(rfmodel, open('model.pkl','wb'))\n",
    "\n",
    "# Loading model to compare the results\n",
    "model = pickle.load(open('model.pkl','rb'))\n",
    "#print(model.predict([[2, 9, 6]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(rfmodel.predict([[3,280,43,57,70,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,1,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        63\n",
      "           1       0.52      0.57      0.54        23\n",
      "           2       0.60      0.50      0.55        12\n",
      "           3       0.75      0.27      0.40        11\n",
      "           4       0.60      0.60      0.60         5\n",
      "           5       0.86      0.86      0.86         7\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       121\n",
      "   macro avg       0.69      0.61      0.63       121\n",
      "weighted avg       0.71      0.71      0.70       121\n",
      "\n",
      "[[55  4  1  1  1  1]\n",
      " [ 9 13  1  0  0  0]\n",
      " [ 2  4  6  0  0  0]\n",
      " [ 1  4  2  3  1  0]\n",
      " [ 2  0  0  0  3  0]\n",
      " [ 1  0  0  0  0  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sankalp\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel=RandomForestClassifier()\n",
    "rfmodel.fit(X_train,y_train)\n",
    "predictions = np.around(rfmodel.predict(X_test))\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sankalp\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81        63\n",
      "           1       0.54      0.61      0.57        23\n",
      "           2       0.67      0.67      0.67        12\n",
      "           3       0.50      0.09      0.15        11\n",
      "           4       0.25      0.20      0.22         5\n",
      "           5       0.60      0.43      0.50         7\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       121\n",
      "   macro avg       0.55      0.48      0.49       121\n",
      "weighted avg       0.66      0.68      0.65       121\n",
      "\n",
      "[[55  5  1  0  2  0]\n",
      " [ 8 14  1  0  0  0]\n",
      " [ 1  2  8  1  0  0]\n",
      " [ 4  1  2  1  1  2]\n",
      " [ 3  1  0  0  1  0]\n",
      " [ 1  3  0  0  0  3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='poly',degree=3) \n",
    "clf.fit(X_train,y_train)\n",
    "predictions = np.around(clf.predict(X_test))\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77        63\n",
      "           1       0.53      0.39      0.45        23\n",
      "           2       0.23      0.25      0.24        12\n",
      "           3       0.40      0.18      0.25        11\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.29      0.29      0.29         7\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       121\n",
      "   macro avg       0.36      0.33      0.33       121\n",
      "weighted avg       0.55      0.57      0.55       121\n",
      "\n",
      "[[53  5  1  1  2  1]\n",
      " [10  9  2  1  0  1]\n",
      " [ 7  0  3  0  1  1]\n",
      " [ 0  3  4  2  0  2]\n",
      " [ 3  0  1  1  0  0]\n",
      " [ 1  0  2  0  2  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sankalp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sankalp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression() \n",
    "clf.fit(X_train,y_train)\n",
    "predictions = np.around(clf.predict(X_test))\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
